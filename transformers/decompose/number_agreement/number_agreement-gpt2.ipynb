{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers \n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from decompose_gpt2 import GPT2LMHeadModelDecomposed\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = pd.read_csv(\"all_VERBs.csv\")[\"WORD\"]\n",
    "verb_ids = []\n",
    "\n",
    "for verb in verbs.iloc:\n",
    "    i = tokenizer.encode(\" \" + verb)\n",
    "    if (len(i) == 1):\n",
    "        verb_ids.append(i[0])\n",
    "\n",
    "verb_ids = torch.Tensor(verb_ids).to(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lq/kd3wh6952vg99n5ppf4srz9w0000gn/T/ipykernel_33749/296677106.py:40: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  number_df = number_df.dropna().reset_index(drop=True).drop(columns=\"token\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject_number</th>\n",
       "      <th>distractor_number</th>\n",
       "      <th>sentence</th>\n",
       "      <th colspan=\"2\" halign=\"left\">verb</th>\n",
       "      <th>verb_tokens</th>\n",
       "      <th>sentence_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601</td>\n",
       "      <td>singular</td>\n",
       "      <td>plural</td>\n",
       "      <td>The athlete behind the bikes</td>\n",
       "      <td>approves</td>\n",
       "      <td>approve</td>\n",
       "      <td>[43770, 14762]</td>\n",
       "      <td>[464, 16076, 2157, 262, 16715]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>singular</td>\n",
       "      <td>plural</td>\n",
       "      <td>The athlete behind the cars</td>\n",
       "      <td>inspires</td>\n",
       "      <td>inspire</td>\n",
       "      <td>[38934, 18330]</td>\n",
       "      <td>[464, 16076, 2157, 262, 5006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603</td>\n",
       "      <td>singular</td>\n",
       "      <td>plural</td>\n",
       "      <td>The athlete behind the cats</td>\n",
       "      <td>engages</td>\n",
       "      <td>engage</td>\n",
       "      <td>[32902, 8209]</td>\n",
       "      <td>[464, 16076, 2157, 262, 11875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604</td>\n",
       "      <td>singular</td>\n",
       "      <td>plural</td>\n",
       "      <td>The athlete behind the cats</td>\n",
       "      <td>remembers</td>\n",
       "      <td>remember</td>\n",
       "      <td>[18140, 3505]</td>\n",
       "      <td>[464, 16076, 2157, 262, 11875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>605</td>\n",
       "      <td>singular</td>\n",
       "      <td>plural</td>\n",
       "      <td>The athlete behind the chairs</td>\n",
       "      <td>observes</td>\n",
       "      <td>observe</td>\n",
       "      <td>[34526, 12414]</td>\n",
       "      <td>[464, 16076, 2157, 262, 18791]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>1795</td>\n",
       "      <td>plural</td>\n",
       "      <td>singular</td>\n",
       "      <td>The women near the dog</td>\n",
       "      <td>engage</td>\n",
       "      <td>engages</td>\n",
       "      <td>[8209, 32902]</td>\n",
       "      <td>[464, 1466, 1474, 262, 3290]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1796</td>\n",
       "      <td>plural</td>\n",
       "      <td>singular</td>\n",
       "      <td>The women near the tree</td>\n",
       "      <td>greet</td>\n",
       "      <td>greets</td>\n",
       "      <td>[12589, 45204]</td>\n",
       "      <td>[464, 1466, 1474, 262, 5509]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1797</td>\n",
       "      <td>plural</td>\n",
       "      <td>singular</td>\n",
       "      <td>The women near the window</td>\n",
       "      <td>avoid</td>\n",
       "      <td>avoids</td>\n",
       "      <td>[3368, 30940]</td>\n",
       "      <td>[464, 1466, 1474, 262, 4324]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1799</td>\n",
       "      <td>plural</td>\n",
       "      <td>singular</td>\n",
       "      <td>The women near the window</td>\n",
       "      <td>engage</td>\n",
       "      <td>engages</td>\n",
       "      <td>[8209, 32902]</td>\n",
       "      <td>[464, 1466, 1474, 262, 4324]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1800</td>\n",
       "      <td>plural</td>\n",
       "      <td>singular</td>\n",
       "      <td>The women near the window</td>\n",
       "      <td>understand</td>\n",
       "      <td>understands</td>\n",
       "      <td>[1833, 14759]</td>\n",
       "      <td>[464, 1466, 1474, 262, 4324]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id subject_number distractor_number  \\\n",
       "correctness                                          \n",
       "0             601       singular            plural   \n",
       "1             602       singular            plural   \n",
       "2             603       singular            plural   \n",
       "3             604       singular            plural   \n",
       "4             605       singular            plural   \n",
       "..            ...            ...               ...   \n",
       "882          1795         plural          singular   \n",
       "883          1796         plural          singular   \n",
       "884          1797         plural          singular   \n",
       "885          1799         plural          singular   \n",
       "886          1800         plural          singular   \n",
       "\n",
       "                                  sentence         verb                \\\n",
       "correctness                                     correct         wrong   \n",
       "0             The athlete behind the bikes     approves       approve   \n",
       "1              The athlete behind the cars     inspires       inspire   \n",
       "2              The athlete behind the cats      engages        engage   \n",
       "3              The athlete behind the cats    remembers      remember   \n",
       "4            The athlete behind the chairs     observes       observe   \n",
       "..                                     ...          ...           ...   \n",
       "882                 The women near the dog       engage       engages   \n",
       "883                The women near the tree        greet        greets   \n",
       "884              The women near the window        avoid        avoids   \n",
       "885              The women near the window       engage       engages   \n",
       "886              The women near the window   understand   understands   \n",
       "\n",
       "                verb_tokens                 sentence_tokens  \n",
       "correctness                                                  \n",
       "0            [43770, 14762]  [464, 16076, 2157, 262, 16715]  \n",
       "1            [38934, 18330]   [464, 16076, 2157, 262, 5006]  \n",
       "2             [32902, 8209]  [464, 16076, 2157, 262, 11875]  \n",
       "3             [18140, 3505]  [464, 16076, 2157, 262, 11875]  \n",
       "4            [34526, 12414]  [464, 16076, 2157, 262, 18791]  \n",
       "..                      ...                             ...  \n",
       "882           [8209, 32902]    [464, 1466, 1474, 262, 3290]  \n",
       "883          [12589, 45204]    [464, 1466, 1474, 262, 5509]  \n",
       "884           [3368, 30940]    [464, 1466, 1474, 262, 4324]  \n",
       "885           [8209, 32902]    [464, 1466, 1474, 262, 4324]  \n",
       "886           [1833, 14759]    [464, 1466, 1474, 262, 4324]  \n",
       "\n",
       "[887 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_df = pd.read_csv(\"nounpp.tsv\", delimiter=\"\\t\")\n",
    "max_length = 16\n",
    "\n",
    "number_df[\"id\"] = number_df[\"id\"].apply(lambda x: int(x[2:]))\n",
    "\n",
    "# only keep sentences that are plural/singular or singular/plural (distractor has different number)\n",
    "number_df[\"subject_distractor_number\"] = number_df[\"subject_distractor_number\"].apply(\n",
    "    lambda x: x if x == \"singular_plural\" or x == \"plural_singular\" else np.nan\n",
    ")\n",
    "number_df.dropna(inplace=True)\n",
    "\n",
    "number_df[\"subject_number\"] = number_df[\"subject_distractor_number\"].apply(lambda x: x.split(\"_\")[0])\n",
    "number_df[\"distractor_number\"] = number_df[\"subject_distractor_number\"].apply(lambda x: x.split(\"_\")[1])\n",
    "\n",
    "number_df[\"verb\"] = number_df[\"sentence\"].apply(lambda x: \" \" + x.split(\" \")[-1])\n",
    "number_df[\"sentence\"] = number_df[\"sentence\"].apply(lambda x: \" \".join(x.split(\" \")[:-1]))\n",
    "\n",
    "number_df = number_df.drop(\n",
    "    columns=[\"subject_distractor_number\"]\n",
    "    ).pivot(index=[\"id\", \"subject_number\", \"distractor_number\", \"sentence\"], columns=[\"correctness\"], values=[\"verb\"]).reset_index()\n",
    "\n",
    "\n",
    "def get_token(correct_token, wrong_token):\n",
    "    # replace with if longer than 1 token\n",
    "    if len(correct_token) > 1 or len(wrong_token) > 1:\n",
    "        return np.nan\n",
    "\n",
    "    return [correct_token[0], wrong_token[0]]\n",
    "\n",
    "number_df[(\"token\", \"correct\")] = tokenizer(number_df[(\"verb\", \"correct\")].to_list())[\"input_ids\"]\n",
    "number_df[(\"token\", \"wrong\")] = tokenizer(number_df[(\"verb\", \"wrong\")].to_list())[\"input_ids\"]\n",
    "\n",
    "number_df[(\"verb_tokens\")] = number_df.apply(\n",
    "    lambda x: get_token(x[(\"token\", \"correct\")], x[(\"token\", \"wrong\")]),\n",
    "    axis=1)\n",
    "\n",
    "number_df[(\"sentence_tokens\")] = tokenizer(number_df[(\"sentence\", \"\")].to_list())[\"input_ids\"]\n",
    "\n",
    "# drop duplicates\n",
    "number_df = number_df.dropna().reset_index(drop=True).drop(columns=\"token\")\n",
    "number_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_component_masks(sentence_tokens):\n",
    "    # prep = [13970, 1474, 2157] # beside, near, behind\n",
    "    prep = tokenizer.encode(' beside near behind')\n",
    "\n",
    "    # always starts with 0, 133\n",
    "    i = 1\n",
    "    The_i = 0\n",
    "    subj_i = []\n",
    "\n",
    "    while sentence_tokens[i] not in prep:\n",
    "        subj_i.append(i)\n",
    "        i += 1\n",
    "        \n",
    "    prep_i = i\n",
    "    the_i = i + 1\n",
    "    distractor_id = []\n",
    "    i += 2\n",
    "\n",
    "    while i < len(sentence_tokens):\n",
    "        distractor_id.append(i)\n",
    "        i += 1\n",
    "        \n",
    "    # place each one in a separate array \n",
    "    component_masks = np.zeros((5, len(sentence_tokens)))\n",
    "    for n, component in enumerate([\n",
    "        The_i, subj_i, prep_i, the_i, distractor_id\n",
    "    ]):\n",
    "        component_masks[n, component] = 1\n",
    "    \n",
    "    return component_masks\n",
    "\n",
    "\n",
    "number_df[\"beta_mask\"] = number_df[\"sentence_tokens\"].apply(make_component_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_model = None\n",
    "\n",
    "def split_pos_neg_contributions(logits):\n",
    "    \"\"\"\n",
    "    shape: (num_contributions + 1 (bias), num_classes)\n",
    "    \"\"\"\n",
    "   # put negative \"positive\" contributions in the negative category\n",
    "    # put negative \"negative\" contributions in the positive category\n",
    "    positive_mask = (logits > 0).astype(int)\n",
    "\n",
    "    positive_logits = logits[..., 1] * positive_mask[..., 1]\n",
    "    positive_logits -= logits[..., 0] * (1 - positive_mask[..., 0])\n",
    "\n",
    "    negative_logits = logits[..., 0] * positive_mask[..., 0]\n",
    "    negative_logits -= logits[..., 1] * (1 - positive_mask[..., 1])\n",
    "\n",
    "    # assert (np.all(positive_logits >= 0))\n",
    "    # assert (np.all(negative_logits >= 0))\n",
    "\n",
    "    binary_logits = np.stack(\n",
    "        [negative_logits, positive_logits], axis=-2\n",
    "    )\n",
    "    # print(binary_logits.shape)\n",
    "    return binary_logits\n",
    "\n",
    "\n",
    "def get_proportion_contribution(n):\n",
    "    beta_masks = torch.tensor(number_df[\"beta_mask\"][n])\n",
    "    verb_tokens = torch.tensor(number_df[\"verb_tokens\"][n])\n",
    "    inputs = torch.tensor(number_df[\"sentence_tokens\"][n])\n",
    "\n",
    "    contribution_logits = torch.zeros((5, 2))\n",
    "\n",
    "    for i, mask in enumerate(beta_masks):\n",
    "        beta_mask = torch.stack([mask, 1 - mask]).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            result = decomposed_model(input_ids=inputs,\n",
    "                            beta_mask=beta_mask)[\"logits\"]\n",
    "            \n",
    "        # result = result[0, -1, :]\n",
    "        # # normalize across entire vocab\n",
    "        # result = result - result[verb_ids].mean()\n",
    "        # result = result / torch.std(result[verb_ids], keepdim=True)\n",
    "        # contribution = result[verb_tokens]\n",
    "        # contribution_logits[i, :] = contribution\n",
    "\n",
    "        result = result[:, -1, :]\n",
    "        result = result - result[:, verb_ids].mean(1, keepdim=True)\n",
    "        result = result / result[:, verb_ids].std(1, keepdim=True)\n",
    "\n",
    "        correct, wrong = split_pos_neg_contributions(result[:, verb_tokens].numpy())\n",
    "        # beta_z_t / z_t\n",
    "        correct = correct[0] / (correct.sum() + 1e-10)\n",
    "        wrong = wrong[0] / (wrong.sum() + 1e-10)\n",
    "        \n",
    "        contribution_logits[i, 0] = correct\n",
    "        contribution_logits[i, 1] = wrong\n",
    "\n",
    "    return contribution_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### GCD w/ fixed bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_model = GPT2LMHeadModelDecomposed.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    debug=False,\n",
    "    shapley_include_bias=False,\n",
    "    generalized=True, \n",
    "    num_contributions=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "contribution_logits = []\n",
    "for i in range(100):\n",
    "    contribution_logits.append(get_proportion_contribution(i))\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "\n",
    "contribution_logits = torch.stack(contribution_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5407, 0.0480],\n",
       "        [0.4395, 0.2156],\n",
       "        [0.4578, 0.1599],\n",
       "        [0.3725, 0.2872],\n",
       "        [0.1809, 0.3719]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_logits.mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n"
     ]
    }
   ],
   "source": [
    "contribution_logits_sp = []\n",
    "contribution_logits_ps = []\n",
    "\n",
    "for i in range(len(number_df)):\n",
    "# for i in range(100):\n",
    "    if number_df[\"subject_number\"][i] == \"singular\":\n",
    "        contribution_logits_sp.append(get_proportion_contribution(i))\n",
    "    else:\n",
    "        contribution_logits_ps.append(get_proportion_contribution(i))\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "\n",
    "contribution_logits_sp = torch.stack(contribution_logits_sp)\n",
    "contribution_logits_ps = torch.stack(contribution_logits_ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5353, 0.0385],\n",
       "        [0.4375, 0.2356],\n",
       "        [0.4637, 0.1839],\n",
       "        [0.3525, 0.2781],\n",
       "        [0.2115, 0.3860]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_logits_sp.mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3040, 0.3017],\n",
       "        [0.6178, 0.1336],\n",
       "        [0.2425, 0.5139],\n",
       "        [0.1563, 0.6640],\n",
       "        [0.1926, 0.6071]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_logits_ps.mean(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CD w/ fixed bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_model = GPT2LMHeadModelDecomposed.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    debug=False,\n",
    "    shapley_include_bias=False,\n",
    "    generalized=False, \n",
    "    num_contributions=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n"
     ]
    }
   ],
   "source": [
    "contribution_logits_sp = []\n",
    "contribution_logits_ps = []\n",
    "\n",
    "for i in range(len(number_df)):\n",
    "# for i in range(100):\n",
    "    if number_df[\"subject_number\"][i] == \"singular\":\n",
    "        contribution_logits_sp.append(get_proportion_contribution(i))\n",
    "    else:\n",
    "        contribution_logits_ps.append(get_proportion_contribution(i))\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "\n",
    "contribution_logits_sp = torch.stack(contribution_logits_sp)\n",
    "contribution_logits_ps = torch.stack(contribution_logits_ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3206, 0.3162],\n",
       "        [0.4249, 0.2105],\n",
       "        [0.4493, 0.1565],\n",
       "        [0.3951, 0.2412],\n",
       "        [0.1902, 0.4667]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_logits_sp.mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2694, 0.3193],\n",
       "        [0.2261, 0.4094],\n",
       "        [0.1498, 0.4709],\n",
       "        [0.2260, 0.4176],\n",
       "        [0.3647, 0.2092]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_logits_ps.mean(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCD w/ permuted bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_model = GPT2LMHeadModelDecomposed.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    debug=False,\n",
    "    shapley_include_bias=True,\n",
    "    generalized=True, \n",
    "    num_contributions=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n"
     ]
    }
   ],
   "source": [
    "contribution_logits_sp = []\n",
    "contribution_logits_ps = []\n",
    "\n",
    "for i in range(len(number_df)):\n",
    "# for i in range(100):\n",
    "    if number_df[\"subject_number\"][i] == \"singular\":\n",
    "        contribution_logits_sp.append(get_proportion_contribution(i))\n",
    "    else:\n",
    "        contribution_logits_ps.append(get_proportion_contribution(i))\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "\n",
    "contribution_logits_sp = torch.stack(contribution_logits_sp)\n",
    "contribution_logits_ps = torch.stack(contribution_logits_ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4156, 0.1172],\n",
       "        [0.4726, 0.1176],\n",
       "        [0.3775, 0.1112],\n",
       "        [0.3851, 0.1372],\n",
       "        [0.2480, 0.2046]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_logits_sp.mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2594, 0.3282],\n",
       "        [0.2190, 0.3734],\n",
       "        [0.1507, 0.3404],\n",
       "        [0.1407, 0.4034],\n",
       "        [0.2184, 0.2696]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution_logits_ps.mean(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CD w/ permuted bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_model = GPT2LMHeadModelDecomposed.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    debug=False,\n",
    "    shapley_include_bias=True,\n",
    "    generalized=False, \n",
    "    num_contributions=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_logits_sp = []\n",
    "contribution_logits_ps = []\n",
    "\n",
    "for i in range(len(number_df)):\n",
    "# for i in range(100):\n",
    "    if number_df[\"subject_number\"][i] == \"singular\":\n",
    "        contribution_logits_sp.append(get_proportion_contribution(i))\n",
    "    else:\n",
    "        contribution_logits_ps.append(get_proportion_contribution(i))\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "\n",
    "contribution_logits_sp = torch.stack(contribution_logits_sp)\n",
    "contribution_logits_ps = torch.stack(contribution_logits_ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_logits_sp.mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_logits_ps.mean(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaphor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
